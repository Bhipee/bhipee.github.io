[🌇](echo/) Hi there👋🏻, I am Yunfei (☁️🪽), a senior researcher at [International Digital Economy Academy (IDEA)](https://idea.edu.cn)<img src='./images/idea.jpg' style='width: 2.5em;'>. 
I am now leading an effort on talking head generation, face tracking, humuan video generation, human-centric 3DGS and video content generation research. If you are seeking any form of **academic cooperation**, please feel free to email me at [liuyunfei@idea.edu.cn](liuyunfei@idea.edu.cn).

I got my Ph.D. degree from Beihang University, advised by Prof. [Feng Lu](http://shi.buaa.edu.cn/lufeng/en/index.htm). Previously, I received my BSc degree in Computer Science from Beijing Institute of Technology in 2017.

<!-- **My research** include the intersection of machine learning, deep learning, pattern recognition, and statistical modeling/inference with applications for computer vision, computational photography, low-level vision, human-computer interaction, and AR/MR.  -->

**My research** aims to build multimodal, highly expressive, lifelike, and immersive interactive agents, covering perception, understanding, reconstruction, and generation of *humans and the world*. *Specifically*: 

1. 🎑 Scene perception and enhancement: [USI3D](https://liuyunfei.net/projects/cvpr20/index.html), [SGRRN](https://dl.acm.org/doi/10.1145/3510821), [SILS](https://arxiv.org/abs/1906.00734).

2. 👀 Human–environment interaction perception: [PnP-GA](https://liuyunfei.net/projects/iccv21/index.html), [GazeOnce](https://github.com/mf-zhang/GazeOnce), [WISWYS](https://ieeexplore.ieee.org/document/9220850).

3. 😏 2D/3D Head and body reconstruction, animation, and generation: [TEASER](https://tinyurl.com/TEASER-project), [GUAVA](https://eastbeanzhang.github.io/GUAVA/), [GPAvatar](https://xg-chu.site/project_gpavatar/), [MODA](https://liuyunfei.net/projects/iccv23-moda/index.html), [HRAvatar](https://eastbeanzhang.github.io/HRAvatar/), [DiffSHEG](https://jeremycjm.github.io/proj/DiffSHEG), [TokenFace](https://liuyunfei.net/).

4. 🎞 Image/Video editing and generation: [Qffusion](https://www.computer.org/csdl/journal/tg/5555/01/11106190/28NPQuwUsaA), [STEM-inv](https://stem-inv.github.io/page/), [AddMe](https://addme-awesome.github.io/page/).

Previously, I also worked on network interpretability AR/VR, and industrial anomaly detection: [Refool](https://arxiv.org/abs/2007.02343), [EGNIA](https://github.com/zhaoyuhsin/Edge-Guided-Near-Eye-Image-Analysis-for-Head-Mounted-Displays), [3DEG](https://ieeexplore.ieee.org/document/9756767), [UTAD](https://arxiv.org/pdf/2103.11671.pdf).

I serve as a reviewer for international conferences and journals, *e.g.*, CVPR, ICCV, NeuIPS, ICLR, ICML, ACM MM, TPAMI, IJCV, PR, TVCG, *etc.*.

> 👏 We are currently looking for self-motivated interns to explore cutting-edge techniques such as Gaussian Splatting and DM/FM. Feel free to [contact me](mailto:liuyunfei@idea.edu.cn) if you are interested. [zhihu](https://zhuanlan.zhihu.com/p/582929545)
